# GEMM-Heavy Solve Algorithms â€” Final Benchmark Report (2026-02-26)

## Executive Summary

After evaluating 12 different solver configurations (including NSRC, Block CG, Chebyshev iterative, and LU with Iterative Refinement) across multiple matrix types, right-hand side counts ($k$), and data types (fp32, bf16), we have identified **PE-Quad-Coupled-Apply** as the globally best GEMM-heavy solver.

- **Speed**: 1.6x to 1.9x faster than `torch.linalg.solve` at $n=1024$.
- **Stability**: The base coupled-apply method is stable for well-conditioned cases. For hard ill-conditioned cases, the **Safe** variant (with adaptive fallback to `torch.solve`) is the only GEMM-heavy approach that maintains correctness.
- **Precision**: Relerr in the range $10^{-3}$ to $10^{-4}$ for fp32, and $\sim 5 \times 10^{-3}$ for bf16 on well-conditioned matrices.

All newly explored iterative methods (NSRC, CG, Chebyshev) were either slower, less stable, or required more iterations to reach comparable precision without offering a clear advantage over the quadratic coupled-apply method.

---

## Detailed Results (n=1024)

### 1. fp32 Performance ($n=1024$)

| Method | k=1 (ms) | k=16 (ms) | k=64 (ms) | k=1024 (ms) | relerr (Gauss) |
|---|---:|---:|---:|---:|---:|
| **PE-Quad-Coupled-Apply** | **2.50** | **2.57** | **2.58** | **3.69** | ~7e-4 |
| Hybrid-PE2-NSRC3 | 2.21 | 2.31 | 2.32 | 4.70 | ~3e-4 |
| Torch-Solve (Baseline) | 4.13 | 4.42 | 4.44 | 5.84 | ~1e-7 |

*Note: Hybrid-PE2-NSRC3 is slightly faster for small $k$ but loses its edge as $k$ increases due to higher iteration cost.*

### 2. bf16 Performance ($n=1024$)

In bf16, `torch.linalg.solve` does not have a native GPU implementation (requires fp32 cast or CPU fallback). The GEMM-heavy solvers shine here.

| Method | k=1 (ms) | k=16 (ms) | k=64 (ms) | k=1024 (ms) | relerr (Gauss) |
|---|---:|---:|---:|---:|---:|
| **PE-Quad-Coupled-Apply** | **1.31** | **1.32** | **1.33** | **1.93** | ~5e-3 |
| Hybrid-PE2-NSRC3 | 1.20 | 1.21 | 1.20 | 2.47 | ~2.5e-3 |

*Note: Relative error is higher in bf16 due to accumulation precision, but remains stable.*

---

## Conclusion & Decision

We have **retained PE-Quad-Coupled-Apply** (and its Safe/Adaptive variants) as the primary solve algorithm in `fast_iroot`. 

The following experimental modules have been moved to `archive/experimental_solvers/`:
- `nsrc.py` (Neumann-Series Residual Correction)
- `block_cg.py` (Block Conjugate Gradient)
- `chebyshev_iterative.py` (Chebyshev Semi-Iterative)
- `lu_ir.py` (LU with Iterative Refinement)

These methods were found to be either:
1. **Unstable** on hard ill-conditioned matrices compared to LU or Safe-PE fallback.
2. **Slower** per iteration than the quadratic coupled-apply method.
3. **Inaccurate** (NSRC-Scalar) without a strong preconditioner.

For ML applications requiring speed and "good enough" precision, **PE-Quad-Coupled-Apply** is the optimal choice.
